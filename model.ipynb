{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.253249Z",
     "start_time": "2019-09-23T08:13:02.373952Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\you\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.265219Z",
     "start_time": "2019-09-23T08:13:05.255244Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_data_from_xlsx(path=\"./src_data.xlsx\",all_features=False):\n",
    "    \"\"\"\n",
    "    Load data from file and decide whether 4 features or all features are kept. \n",
    "    \"\"\"\n",
    "    data = pd.read_excel(path)\n",
    "    if not all_features:\n",
    "        keep_features = [\"A_NIH\", \"A_THALAMUS2\", \"MIDDLE_BAO\", \"BATMAN\", \"FR\"]\n",
    "        data = data.drop(\n",
    "            [feature for feature in data.columns if feature not in keep_features],\n",
    "            axis=1,\n",
    "        )\n",
    "    print(\"Data loaded from xlsx.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.443752Z",
     "start_time": "2019-09-23T08:13:05.267212Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(data,categoricals=[\"A_THALAMUS2\", \"MIDDLE_BAO\", \"BATMAN\"]):\n",
    "    \"\"\"One-hot encode categorical data\"\"\"\n",
    "    for column in categoricals:\n",
    "        data = pd.get_dummies(data, columns=[column], prefix=[column])\n",
    "    \n",
    "    print(\"One-hot encode categorical data.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.560431Z",
     "start_time": "2019-09-23T08:13:05.448729Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale(X_train):\n",
    "    \"\"\"Scale independent variables\"\"\"\n",
    "    X_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    X_train_scaled = X_scaler.fit_transform(X_train.values.astype(float))\n",
    "\n",
    "    return [X_train_scaled,X_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.644204Z",
     "start_time": "2019-09-23T08:13:05.565440Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_pipeline(data, output='FR',test_size=.2):\n",
    "    \"\"\"\n",
    "    Split data into variables\n",
    "    Arguments: Pandas dataframe, output column (dependent variable),size of test set(account for all data)\n",
    "    Returns: List of scaled and unscaled dependent and independent variables\n",
    "    \"\"\"\n",
    "    y, X = data.iloc[:, -1], data.iloc[:, :-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop([output], axis=1), data[output], test_size=test_size, random_state=1)\n",
    "    [X_train_scaled,X_scaler] = scale(X_train)\n",
    "    \n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    y_train = enc.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "    y_test = enc.fit_transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "    return [np.array(X_train_scaled),y_train,np.array(X_test),y_test,X_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.728009Z",
     "start_time": "2019-09-23T08:13:05.646198Z"
    }
   },
   "outputs": [],
   "source": [
    "class Recording():\n",
    "    '''\n",
    "    Define a dataframe used to record every experiment\n",
    "    Arguments:parameters to be recored\n",
    "    '''\n",
    "    def __init__(self,index=None): \n",
    "        if not index:\n",
    "            self.index = (\n",
    "            [\n",
    "                \"training_epochs\",\n",
    "                \"batch_size\",\n",
    "                \"is_lr_decay\",\n",
    "                \"init_learning_rate\",\n",
    "                \"decay_rate\",\n",
    "                \"decay_steps\",\n",
    "                \"num_hidden_layers\",\n",
    "                \"num_units_each_layer\",\n",
    "                \"is_dropout\",\n",
    "                \"dropout_rate\",\n",
    "            ]\n",
    "            + [\"accuracy_\" + str(index) for index in range(1, 11)]\n",
    "            + [\"auc_\" + str(index) for index in range(1, 11)]\n",
    "            + [\"avg_accuracy\", \"avg_auc\"]\n",
    "        )\n",
    "        else:\n",
    "            self.index = index\n",
    "    def getIndex(self):\n",
    "        return self.index\n",
    "    def getRecordFile(self):\n",
    "        return pd.DataFrame(columns=self.index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:05.818736Z",
     "start_time": "2019-09-23T08:13:05.733996Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_pipeline():\n",
    "    data = load_data_from_xlsx()\n",
    "    data = one_hot_encode(data)\n",
    "    X_train_scaled, y_train, X_test, y_test, X_scaler = split_pipeline(data)\n",
    "    print(\"Training set and test set are generated.\")\n",
    "    return X_train_scaled, y_train, X_test, y_test, X_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:06.081054Z",
     "start_time": "2019-09-23T08:13:05.820732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Network Ready!\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning-Based Model for Prediction of Outcomes in Acute Stroke\n",
    "# 3 hidden layers with 15 artificial neural network units each were used\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# parameters\n",
    "init_learning_rate = 0.006\n",
    "training_epochs = 600\n",
    "batch_size = 10\n",
    "display_step = 10\n",
    "decay_rate = 0.96 \n",
    "decay_steps = 50 \n",
    "use_learning_decay = True\n",
    "use_dropout = True\n",
    "\n",
    "# Networks Parameters\n",
    "X_train_scaled,y_train,X_test,y_test,X_scaler = data_pipeline() # here just be used to initialize two parameters of 'dim' and 'nclass' \n",
    "dim = X_train_scaled.shape[1]\n",
    "nclass = y_train.shape[1]\n",
    "n_hidden_1 = 15\n",
    "n_hidden_2 = 15\n",
    "n_hidden_3 = 15\n",
    "n_input = dim\n",
    "n_classes = nclass\n",
    "\n",
    "# tf.Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "dropout_keep_prob = tf.placeholder('float')\n",
    "learning_rate = tf.placeholder('float')\n",
    "global_step = tf.Variable(tf.constant(0))\n",
    "lr = tf.train.exponential_decay(init_learning_rate,global_step,decay_steps,decay_rate)\n",
    "\n",
    "# Store layers weight & bias\n",
    "stddev = 0.1  # important\n",
    "weights = {\n",
    "    \"h1\": tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=stddev)),\n",
    "    \"h2\": tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=stddev)),\n",
    "    \"h3\": tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3], stddev=stddev)),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_hidden_3, n_classes], stddev=stddev))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b1\": tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\": tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"b3\": tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_classes])),\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def multiplayer_perception(_X, _weights, _biases,_keep_prob):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights[\"h1\"]), _biases[\"b1\"]))  \n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights[\"h2\"]), _biases[\"b2\"]))\n",
    "    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, _weights[\"h3\"]), _biases[\"b3\"]))\n",
    "    if use_dropout:\n",
    "        layer_3 = tf.nn.dropout(layer_3,_keep_prob)\n",
    "    out = tf.add(tf.matmul(layer_3, _weights[\"out\"]) , _biases[\"out\"]) \n",
    "    return out\n",
    "print(\"Network Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:06.322390Z",
     "start_time": "2019-09-23T08:13:06.083030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready\n"
     ]
    }
   ],
   "source": [
    "# Construct Model\n",
    "pred = multiplayer_perception(x,weights,biases,dropout_keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))    \n",
    "accu = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "\n",
    "# Initializing the variables\n",
    "\n",
    "print (\"Functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:06.377243Z",
     "start_time": "2019-09-23T08:13:06.324385Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train_scaled,y_train,X_test,y_test,X_scaler):\n",
    "    ntrain = y_train.shape[0]\n",
    "    ntest = y_test.shape[0]\n",
    "    # Launch the graph\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        if use_learning_decay:\n",
    "            lr_ = sess.run(lr,feed_dict={global_step:epoch})\n",
    "        else:\n",
    "            lr_ = init_learning_rate\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(ntrain/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            randidx = np.random.randint(ntrain, size=batch_size)\n",
    "            batch_xs = X_train_scaled[randidx, :]\n",
    "            batch_ys = y_train[randidx, :]\n",
    "            # Fit training using batch data\n",
    "            if use_dropout:\n",
    "                sess.run(optm, feed_dict={x: batch_xs, y: batch_ys,dropout_keep_prob:0.8,learning_rate:lr_})\n",
    "            else:\n",
    "                sess.run(optm, feed_dict={x: batch_xs, y: batch_ys,dropout_keep_prob:1.,learning_rate:lr_})\n",
    "            # Compute average loss\n",
    "            avg_cost += sess.run(cost, \n",
    "                    feed_dict={x: batch_xs, y: batch_ys,dropout_keep_prob:1.0})/total_batch\n",
    "            # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch: %03d/%03d ,learning_rate:%.6f,cost: %.9f\" % \n",
    "                   (epoch+1, training_epochs, lr_,avg_cost))\n",
    "            train_acc = sess.run(accu, feed_dict={x: X_train_scaled, y: y_train,dropout_keep_prob:1.0})\n",
    "            print (\" Training accuracy: %.3f\" % (train_acc))\n",
    "            test_acc,auc = evaluate(sess,X_test,y_test,X_scaler)\n",
    "            print (\" Test accuracy: %.3f\" % (test_acc))\n",
    "            print (\" Test ROC_AUC: %.3f\" % (auc))\n",
    "    print (\"Optimization Finished!\")\n",
    "    test_acc,auc = evaluate(sess,X_test,y_test,X_scaler)\n",
    "    sess.close()\n",
    "    return test_acc , auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:06.501933Z",
     "start_time": "2019-09-23T08:13:06.383228Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sess,X_test,y_test,X_scaler):\n",
    "    X_test_scaled = X_scaler.transform(X_test.astype(float))\n",
    "    test_acc = sess.run(accu, feed_dict={x: X_test_scaled, y: y_test, dropout_keep_prob: 1.0})\n",
    "    probs = sess.run(tf.sigmoid(pred),feed_dict={x: X_test_scaled, y: y_test,dropout_keep_prob:1.0})[:,1]\n",
    "    auc = roc_auc_score(np.argmax(y_test,1),probs)\n",
    "    return [test_acc,auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:13:06.611618Z",
     "start_time": "2019-09-23T08:13:06.502906Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiments_and_recording():\n",
    "    rec = Recording()\n",
    "    record = rec.getRecordFile()\n",
    "    accuracy_10_runs = []\n",
    "    auc_10_runs = []\n",
    "    one_10_runs = [\n",
    "                    training_epochs,\n",
    "                    batch_size,\n",
    "                    False,\n",
    "                    init_learning_rate,\n",
    "                    decay_rate,\n",
    "                    decay_steps,\n",
    "                    3,\n",
    "                    (n_hidden_1,n_hidden_2,n_hidden_3),\n",
    "                    False,\n",
    "                    1\n",
    "                ]\n",
    "    for i in range(10):\n",
    "        X_train_scaled,y_train,X_test,y_test,X_scaler = data_pipeline()\n",
    "        acc,auc = train(X_train_scaled,y_train,X_test,y_test,X_scaler)\n",
    "        accuracy_10_runs.append(acc)\n",
    "        auc_10_runs.append(auc)\n",
    "    one_10_runs.extend(accuracy_10_runs)\n",
    "    one_10_runs.extend(auc_10_runs)\n",
    "    one_10_runs.append(np.mean(accuracy_10_runs))\n",
    "    one_10_runs.append(np.mean(auc_10_runs))\n",
    "    record = record.append(pd.Series(one_10_runs,index=rec.getIndex()),ignore_index=True)\n",
    "    record.to_csv('record.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T08:14:23.816088Z",
     "start_time": "2019-09-23T08:13:06.614637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "WARNING:tensorflow:From c:\\users\\you\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.692171282\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.388295702\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.581687470\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.425460077\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.385052158\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.397766183\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.476657574\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.368866831\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.335388866\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.342882377\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.468525703\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.399570930\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.371562113\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.306421026\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.286904076\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.308037856\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.325732145\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.373426451\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.338703828\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.242185392\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.264553070\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.355118501\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.362253655\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.386786782\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.329538941\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.258137691\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.259710294\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.235404213\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.207723119\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.376548111\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.271252347\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.419365498\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.275702229\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.285830021\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.285984255\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.310652513\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.352352851\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.240192189\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.242558904\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.366129943\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.322477054\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.221852316\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.819\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.316844309\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.320783314\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.819\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.198361464\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.819\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.220987516\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.220888466\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.812\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.258492800\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.302218646\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.228120073\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.812\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.300287682\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.804\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.286742326\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.812\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.208275917\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.804\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.234904340\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.804\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.246546806\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.812\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.266773486\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.819\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.270499291\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.804\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.265934661\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.804\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.308957779\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.804\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.223147867\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.819\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.669856687\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.435567309\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.482230292\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.380537131\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.377529797\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.450280362\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.484935237\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.387765245\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.351413361\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.391907521\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.535899821\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.334013209\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.361982354\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.349065319\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.263177119\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.397299619\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.366954532\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.404462672\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.295791601\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.306881961\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.194283842\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.216920770\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.253771111\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.318862829\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.312591299\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.295130175\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.256902387\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.297302608\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.305166951\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.233434354\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.303536572\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.251139474\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.351184265\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.310557049\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.253546807\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.250905233\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.252153830\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.308228027\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.201094237\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.211332588\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.232916931\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.302211851\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.346372002\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.211453147\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.241082909\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.283189381\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.166544394\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.239878908\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.235257148\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.227818348\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.195453021\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.203847893\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.213003946\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.264170022\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.264653305\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.256190935\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.231825059\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.215706225\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.247394613\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.220746808\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.808\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.683019598\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.386716906\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.380156784\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.366788776\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.354018523\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.495343614\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.333874179\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.480026480\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.441374956\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.478664160\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.376377319\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.359221768\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.328588315\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.328982136\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.297934903\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.419380761\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.316541905\n",
      " Training accuracy: 0.783\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.334959779\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.250212101\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.327641124\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.284467207\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.251304022\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.330233604\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.236774545\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.321395846\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.297157583\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.262323519\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.326498025\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.255230094\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.285562499\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.181266896\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.356741178\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.318813074\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.332204049\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.280428981\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.268588557\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.252719985\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.260612754\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.222197343\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.199496380\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.376425450\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.278453135\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.207127843\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.234836256\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.274001542\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.240267643\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.224303989\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.253279205\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.819\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.284319745\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.285760853\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.835\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.289908268\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.317287836\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.838\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.302827953\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.838\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.254712542\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.835\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.280949303\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.838\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.251195901\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.835\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.282368923\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.838\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.236602017\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.838\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.297551974\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.835\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.354426535\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.835\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.706935773\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.458453337\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.588548495\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.429514592\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.401379625\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.443878838\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.416053409\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.333753506\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.480747397\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.464356646\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.423765040\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.369195943\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.234588428\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.376308293\n",
      " Training accuracy: 0.815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.362521898\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.236383134\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.315536857\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.275520030\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.338805305\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.266795170\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.283335532\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.309069398\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.332685775\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.317696033\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.389342053\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.199600998\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.282367625\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.256564526\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.310462918\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.335001908\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.252695214\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.253656302\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.305973099\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.257042609\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.301103825\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.213538137\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.221924758\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.259533492\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.301032459\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.203257406\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.251342093\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.283218315\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.192541819\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.796\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.250323993\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.245811938\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.257131048\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.231322105\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.246772394\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.259645838\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.272698460\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.243923651\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.269239432\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.196349264\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.209425090\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.197082309\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.272981683\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.253318457\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.242687761\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.252117607\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.274025217\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.800\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.674527321\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.409882643\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.333659584\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.440832206\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.310973118\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.405993140\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.366384162\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.400979612\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.304404491\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.352388362\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.482832359\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.461219620\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.434797840\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.380523778\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.431076571\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.357884400\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.298346778\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.373640547\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.402451995\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.299640233\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.273758639\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.352827700\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.293558978\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.283647526\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.342406117\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.309843643\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.322202270\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.292496230\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.314041170\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.322371292\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.338693351\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.256094249\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.831\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.314192722\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.250663720\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.219472907\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.236048426\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.831\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.241574724\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.831\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.258986354\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.297630949\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.281551879\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.274296458\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.303453045\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.303709429\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.292233921\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.285529046\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.313575958\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.269631672\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.328803241\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.196631414\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.334755923\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.196173288\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.278361569\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.300632761\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.391096392\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.285858629\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.250660315\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.288685718\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.187378135\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.258762305\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.272058743\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.683688740\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.389678035\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.511127681\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.602315280\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.362198868\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.685\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.464962857\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.360215649\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.389803390\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.345312362\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.375343397\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.464772969\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.490275160\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.692\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.362020190\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.436721318\n",
      " Training accuracy: 0.870\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.347366489\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.349046046\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.480027591\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.327740252\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.385041555\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.258553805\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.298601412\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.385648958\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.266243308\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.331429622\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.222591715\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.261997094\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.287675255\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.277080727\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.280220075\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.321459818\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.302616109\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.289737880\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.198792380\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.265505757\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.213805239\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.237138088\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.245883620\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.223368492\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.227531941\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.221654944\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.217119018\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.249010044\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.240617486\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.239634174\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.264194793\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.226347433\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.260048047\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.258749193\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.229774589\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.255697313\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.212599957\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.245013870\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.267933446\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.221019783\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.211049325\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.332070604\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.265069611\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.274619081\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.259520473\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.291152966\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.649663342\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.488680126\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.529747299\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.439335297\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.685\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.365531855\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.677\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.335269120\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.359841959\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.410329249\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.317448831\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.415273286\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.266367822\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.321934882\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.306100635\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.372527159\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.344031759\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.293980618\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.387390256\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.455469151\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.345317364\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.335465621\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.379540843\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.279703868\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.328356465\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.381420122\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.399968619\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.351768855\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.305823028\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.311866207\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.259759718\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.274891739\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.331377702\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.311867707\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.364611433\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.248978813\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.291513437\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.258756151\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.279770941\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.181853784\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.290405145\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.302503753\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.272963943\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.367569269\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.364591862\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.306182168\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.259645378\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.331863692\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.219259717\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.201764324\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.212723640\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.243774636\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.393578185\n",
      " Training accuracy: 0.880\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.250365073\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.236082737\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.282720147\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.304744420\n",
      " Training accuracy: 0.870\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.320600021\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.215923150\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.321120106\n",
      " Training accuracy: 0.870\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.204487400\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.266872163\n",
      " Training accuracy: 0.870\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.657508426\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.359683086\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.336660587\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.467081403\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.692\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.312915900\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.340393032\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.384286152\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.484156176\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.692\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.428244159\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.407496202\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.708\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.296634081\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.283311766\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.353523950\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.692\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.523947014\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.289618747\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.300549587\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.367932331\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.331641340\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.317725211\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.239547802\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.403879116\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.311458156\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.272926071\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.231484641\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.226923815\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.287499017\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.243952839\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.330366196\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.306097906\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.244080909\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.407340778\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.270538943\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.378422476\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.298475445\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.304513542\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.312139979\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.217003297\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.224003817\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.290092185\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.272757336\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.294481471\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.264771764\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.348687741\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.207735732\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.362848591\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.819\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.308433187\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.344444168\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.247475722\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.384049488\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.266010476\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.321970402\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.271938377\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.333442303\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.347082247\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.266545532\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.247940160\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.368826785\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.259446527\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.203101903\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.329749607\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.670170956\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.417040649\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.431437628\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.394268115\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.352627490\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.299967741\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.335882369\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.431308208\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.374821676\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.322055116\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.323379700\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.385911553\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.319048787\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.383030261\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.388815926\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.305453973\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.305204852\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.279329507\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.335009797\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.334787543\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.367366935\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.273848688\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.271668808\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.252833633\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.293057430\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.777\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.263147933\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.241155926\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.306554511\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.218721449\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.291010474\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.373343122\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.273209259\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.284291704\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.259422698\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.239667929\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.265010245\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.192699619\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.346973163\n",
      " Training accuracy: 0.870\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.166811832\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.261090404\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.313033563\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.227250052\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.307830163\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.257529858\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.258454771\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.253300661\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.245095592\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.312678693\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.269198218\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.234151759\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.283633509\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.208388253\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.230255722\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.267897223\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.243693266\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.193492454\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.249315408\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.234531861\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.191591573\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.210831788\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.762\n",
      "Optimization Finished!\n",
      "Data loaded from xlsx.\n",
      "One-hot encode categorical data.\n",
      "Training set and test set are generated.\n",
      "Epoch: 010/600 ,learning_rate:0.005956,cost: 0.677746163\n",
      " Training accuracy: 0.565\n",
      " Test accuracy: 0.565\n",
      " Test ROC_AUC: 0.769\n",
      "Epoch: 020/600 ,learning_rate:0.005908,cost: 0.455640483\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.731\n",
      "Epoch: 030/600 ,learning_rate:0.005860,cost: 0.504526324\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 040/600 ,learning_rate:0.005812,cost: 0.359436729\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.692\n",
      "Epoch: 050/600 ,learning_rate:0.005765,cost: 0.421610200\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.723\n",
      "Epoch: 060/600 ,learning_rate:0.005718,cost: 0.545209302\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.692\n",
      "Epoch: 070/600 ,learning_rate:0.005671,cost: 0.421216316\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 080/600 ,learning_rate:0.005625,cost: 0.417752981\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.700\n",
      "Epoch: 090/600 ,learning_rate:0.005579,cost: 0.375943432\n",
      " Training accuracy: 0.859\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.715\n",
      "Epoch: 100/600 ,learning_rate:0.005534,cost: 0.393950139\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.609\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 110/600 ,learning_rate:0.005489,cost: 0.298404673\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.738\n",
      "Epoch: 120/600 ,learning_rate:0.005444,cost: 0.298678696\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 130/600 ,learning_rate:0.005400,cost: 0.360447375\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.754\n",
      "Epoch: 140/600 ,learning_rate:0.005356,cost: 0.384670355\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.746\n",
      "Epoch: 150/600 ,learning_rate:0.005313,cost: 0.301217046\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 160/600 ,learning_rate:0.005270,cost: 0.291465087\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 170/600 ,learning_rate:0.005227,cost: 0.226183387\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.762\n",
      "Epoch: 180/600 ,learning_rate:0.005184,cost: 0.352230795\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 190/600 ,learning_rate:0.005142,cost: 0.359925307\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 200/600 ,learning_rate:0.005100,cost: 0.366911538\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 210/600 ,learning_rate:0.005059,cost: 0.355445796\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 220/600 ,learning_rate:0.005018,cost: 0.330141149\n",
      " Training accuracy: 0.793\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 230/600 ,learning_rate:0.004977,cost: 0.238249508\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 240/600 ,learning_rate:0.004936,cost: 0.263939712\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 250/600 ,learning_rate:0.004896,cost: 0.310613990\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 260/600 ,learning_rate:0.004856,cost: 0.331386965\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 270/600 ,learning_rate:0.004817,cost: 0.240321310\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 280/600 ,learning_rate:0.004778,cost: 0.292742599\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 290/600 ,learning_rate:0.004739,cost: 0.278203894\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.652\n",
      " Test ROC_AUC: 0.785\n",
      "Epoch: 300/600 ,learning_rate:0.004700,cost: 0.256284152\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 310/600 ,learning_rate:0.004662,cost: 0.280498393\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 320/600 ,learning_rate:0.004624,cost: 0.307429330\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 330/600 ,learning_rate:0.004587,cost: 0.201311295\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 340/600 ,learning_rate:0.004549,cost: 0.239644782\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 350/600 ,learning_rate:0.004512,cost: 0.214320107\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 360/600 ,learning_rate:0.004476,cost: 0.243730689\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 370/600 ,learning_rate:0.004439,cost: 0.322841237\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 380/600 ,learning_rate:0.004403,cost: 0.308020952\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 390/600 ,learning_rate:0.004367,cost: 0.244144047\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 400/600 ,learning_rate:0.004332,cost: 0.252363390\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n",
      "Epoch: 410/600 ,learning_rate:0.004297,cost: 0.251845229\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 420/600 ,learning_rate:0.004262,cost: 0.226304816\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 430/600 ,learning_rate:0.004227,cost: 0.186071887\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 440/600 ,learning_rate:0.004193,cost: 0.171565459\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 450/600 ,learning_rate:0.004159,cost: 0.331368251\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.831\n",
      "Epoch: 460/600 ,learning_rate:0.004125,cost: 0.245606178\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 470/600 ,learning_rate:0.004091,cost: 0.198578249\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480/600 ,learning_rate:0.004058,cost: 0.226548795\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 490/600 ,learning_rate:0.004025,cost: 0.213117175\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 500/600 ,learning_rate:0.003992,cost: 0.268115323\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.808\n",
      "Epoch: 510/600 ,learning_rate:0.003960,cost: 0.215212072\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.831\n",
      "Epoch: 520/600 ,learning_rate:0.003928,cost: 0.262660324\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 530/600 ,learning_rate:0.003896,cost: 0.230258171\n",
      " Training accuracy: 0.837\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 540/600 ,learning_rate:0.003864,cost: 0.223184306\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 550/600 ,learning_rate:0.003833,cost: 0.237276182\n",
      " Training accuracy: 0.848\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 560/600 ,learning_rate:0.003801,cost: 0.236596863\n",
      " Training accuracy: 0.804\n",
      " Test accuracy: 0.696\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 570/600 ,learning_rate:0.003770,cost: 0.243221760\n",
      " Training accuracy: 0.815\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.823\n",
      "Epoch: 580/600 ,learning_rate:0.003740,cost: 0.242425340\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Epoch: 590/600 ,learning_rate:0.003709,cost: 0.203750061\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.783\n",
      " Test ROC_AUC: 0.815\n",
      "Epoch: 600/600 ,learning_rate:0.003679,cost: 0.282302865\n",
      " Training accuracy: 0.826\n",
      " Test accuracy: 0.739\n",
      " Test ROC_AUC: 0.800\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "experiments_and_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "371px",
    "left": "1104px",
    "right": "20px",
    "top": "120px",
    "width": "316px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
